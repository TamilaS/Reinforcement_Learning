{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atari_DQN_youtube.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNWw+K5Ksk6/iivmdzJU4OS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oUYPan5ag-k",
        "outputId": "1056b268-2b1b-4817-e506-42dd8efaec04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pygame\n",
            "  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pygame\n",
            "Successfully installed pygame-2.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install pygame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch gym\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfrF5D1Jarvy",
        "outputId": "92778409-6bb5-43cc-dbdb-a9cbf56fbd57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.6)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # pip install zlib1g-dev cmake\n",
        "!apt install swig cmake libopenmpi-dev zlib1g-dev\n",
        "!pip install stable-baselines[mpi]==2.8.0 box2d box2d-kengz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB3omeXPayOr",
        "outputId": "30b26931-97c0-428f-ba04-a1d9734315e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libopenmpi-dev is already the newest version (2.1.1-8).\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2.1).\n",
            "zlib1g-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 40 not upgraded.\n",
            "Need to get 1,100 kB of archives.\n",
            "After this operation, 5,822 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 1,100 kB in 1s (1,422 kB/s)\n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 155501 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up swig (3.0.12-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting stable-baselines[mpi]==2.8.0\n",
            "  Downloading stable_baselines-2.8.0-py3-none-any.whl (222 kB)\n",
            "\u001b[K     |████████████████████████████████| 222 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting box2d\n",
            "  Downloading Box2D-2.3.10-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 98.5 MB/s \n",
            "\u001b[?25hCollecting box2d-kengz\n",
            "  Downloading Box2D-kengz-2.3.3.tar.gz (425 kB)\n",
            "\u001b[K     |████████████████████████████████| 425 kB 87.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.8.0) (3.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.8.0) (1.1.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.8.0) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.8.0) (1.21.6)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.10.9 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.8.0) (0.17.3)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.8.0) (1.3.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.8.0) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.8.0) (1.4.1)\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.3.tar.gz (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 63.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.8.0) (1.5.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.8.0) (0.2.9)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.10.9->stable-baselines[mpi]==2.8.0) (0.16.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.8.0) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.8.0) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.8.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.8.0) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->stable-baselines[mpi]==2.8.0) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines[mpi]==2.8.0) (2022.1)\n",
            "Building wheels for collected packages: box2d-kengz, mpi4py\n",
            "  Building wheel for box2d-kengz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-kengz: filename=Box2D_kengz-2.3.3-cp37-cp37m-linux_x86_64.whl size=2050821 sha256=1913dc792a6c7664b81d87c0449389c7271b88f03093c3c41fa3c4d7d0bd5276\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/6d/6a/6ff76731fd9e8efbd1cdc6111e98b2dd0f1872184d7c28939c\n",
            "  Building wheel for mpi4py (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.3-cp37-cp37m-linux_x86_64.whl size=2185335 sha256=92d64fa1c8785ab67fcd70de77c4c1e62b3266bbae1eaec469ea729de91f861e\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/07/14/6a0c63fa2c6e473c6edc40985b7d89f05c61ff25ee7f0ad9ac\n",
            "Successfully built box2d-kengz mpi4py\n",
            "Installing collected packages: stable-baselines, mpi4py, box2d-kengz, box2d\n",
            "Successfully installed box2d-2.3.10 box2d-kengz-2.3.3 mpi4py-3.1.3 stable-baselines-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cmake\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-sKRDU5bABe",
        "outputId": "d77eeaea-9bea-4c6d-cb5a-6212692cd4d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cmake in /usr/local/lib/python3.7/dist-packages (3.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import gym\n",
        "from collections import deque\n",
        "import itertools\n",
        "import numpy as np\n",
        "import random\n"
      ],
      "metadata": {
        "id": "F-hY9BX6bCCU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import torch.distributed.rpc\n",
        "from torch import nn\n",
        "import torch\n",
        "import gym\n",
        "from collections import deque\n",
        "import itertools\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from baselines_wrappers import DummyVecEnv, SubprocVecEnv, Monitor\n",
        "from pytorch_wrappers import make_atari_deepmind, BatchedPytorchFrameStack, PytorchLazyFrames\n",
        "\n",
        "import msgpack\n",
        "from msgpack_numpy import patch as msgpack_numpy_patch\n",
        "msgpack_numpy_patch()\n",
        "\n",
        "\n",
        "GAMMA=0.99\n",
        "BATCH_SIZE=32\n",
        "BUFFER_SIZE=int(le6)\n",
        "MIN_REPLAY_SIZE=1000\n",
        "EPSILON_START=1.0\n",
        "EPSILON_END=0.1\n",
        "EPSILON_DECAY=int(le6)\n",
        "TARGET_UPDATE_FREQ = 10000\n",
        "NUM_ENVS = 4\n",
        "LR = 2.5e-4\n",
        "SAVE_PATH = './atari_model.pack'\n",
        "SAVE_INTERVAL = 10000\n",
        "LOG_DIR ='./logs/atari'\n",
        "LOG_INTERVAL= 1000\n",
        "\n",
        "def nature_cnn(observastion_space, depths = (32, 64, 64), final_layer =512):  #from the doc Nasture journal\n",
        "    n_input_channels = observastion_space.shape[0]\n",
        "\n",
        "    cnn = nn.Sequential(\n",
        "        nn.Conv2d(n_input_channels, depths[0], kernel_size=8, stride=4),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(depths[0], depths[1], kernel_size=4, stride=2),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(depths[1], depths[2], kernel_size=3, stride=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Flatten())\n",
        "\n",
        "    with torch.no_grad():\n",
        "        n_flatten = cnn(torch.as_tensor(observastion_space.sample()[None]).float()).shape[1]  #forward pass through cnn\n",
        "\n",
        "    out = nn.Sequential(cnn, nn.Linear(n_flatten, final_layer), nn.ReLU())\n",
        "    return out\n",
        "\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, env, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_actions = env.action_space.n\n",
        "        self.device = device\n",
        "        #in_features = int(np.prod(env.observation_space.shape))  #input is a 3d tensor\n",
        "\n",
        "        conv_net = nature_cnn(env.observation_space.shape)\n",
        "\n",
        "        self.net = nn.Sequential(conv_net, Linear(512, self.num_actions))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "    def act(self, obses , epsilon):\n",
        "        obs_t = torch.as_tensor(obses, dtype=torch.float32, device = self.device)\n",
        "        q_values = self(obses_t)\n",
        "        max_q_indices = torch.argmax(q_values, dim=1)[0]\n",
        "        actions = max_q_indices.detach().tolist()\n",
        "\n",
        "        for i in range(len(actions)):\n",
        "            rnd_sample = random.random()\n",
        "            if rnd_sample <= epsilon:\n",
        "                actions[i] =random.randint(0, self.num_actions - 1)\n",
        "\n",
        "        return actions\n",
        "\n",
        "    def compute_loss(self, transitions, target_net):\n",
        "        obses = [t[0] for t in transitions]\n",
        "        actions = np.asarray([t[1] for t in transitions])\n",
        "        rews = np.asarray([t[2] for t in transitions])\n",
        "        dones = np.asarray([t[3] for t in transitions])\n",
        "        new_obses = [t[4] for t in transitions]\n",
        "\n",
        "        if isinstance(obses[0], PytorchLazyFrames):\n",
        "            obses = np.stack([o.get_frames() for o in obses])  # converts into numpy array\n",
        "            new_obses = np.stack([o.get_frames() for o in obses])\n",
        "        else:\n",
        "            obses = np.asarray(obses)\n",
        "            new_obses = np.asarray(new_obses)\n",
        "\n",
        "\n",
        "        obses_t = torch.as_tensor(obses, dtype=torch.float32, device = self.device)\n",
        "        actions_t = torch.as_tensor(actions, dtype=torch.int64, device = self.device).unsqueeze(-1)\n",
        "        rews_t = torch.as_tensor(rews, dtype=torch.float32, device = self.device).unsqueeze(-1)\n",
        "        dones_t = torch.as_tensor(dones, dtype=torch.float32, device = self.device).unsqueeze(-1)\n",
        "        new_obses_t = torch.as_tensor(new_obses, dtype=torch.float32, device = self.device)\n",
        "\n",
        "        # Compute Targets\n",
        "        # targets = r + gamma * target q vals * (1 - dones)\n",
        "        target_q_values = target_net(new_obses_t)\n",
        "        max_target_q_values = target_q_values.max(dim=1, keepdim=True)[0]\n",
        "\n",
        "        targets = rews_t + GAMMA * (1 - dones_t) * max_target_q_values\n",
        "\n",
        "        # Compute Loss\n",
        "        q_values = self(obses_t)\n",
        "        action_q_values = torch.gather(input=q_values, dim=1, index=actions_t)\n",
        "\n",
        "        loss = nn.functional.smooth_l1_loss(action_q_values, targets)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def save(self, save_path ):\n",
        "        params = {k: t.detach().cpu().numpy() for k,t in self.state_dict().items()}    #datas with numpy array rather than tensors\n",
        "        params_data = msgpack.dumps(params)\n",
        "\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        with open (save_path, 'wb') as f: #open as binary data\n",
        "            f.write(params_data)\n",
        "\n",
        "    def load(self, load_path):\n",
        "        if not os.path.exists(load_path):\n",
        "            raise FileNotFoundError(load_path)\n",
        "        with open(load_path, 'rb') as f:\n",
        "            params_numpy = msgpack.loads(f.read())\n",
        "\n",
        "        params = {k: torch.as_tensor(v, device = self.device) for k,v in params_numpy.items()} #transfor to tensor\n",
        "        self.load_state_dict(params)#loading\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#env = gym.make('CartPole-v0')\n",
        "make_env =lambda: Monitor(make_atari_deepmind('Breakout-v0'), allow_early_resets = True)\n",
        "\n",
        "vec_env = DummyVecEnv([make_env for _ in range(NUM_ENVS)]) #runs env in sequence\n",
        "#env = SubprocVecEnv([make_env for _ in NUM_ENVS]) #each of the env in parallel\n",
        "\n",
        "env = BatchedPytorchFrameStack(vec_env, k=4)\n",
        "\n",
        "replay_buffer = deque(maxlen=BUFFER_SIZE)\n",
        "epinfos_buffer = deque([], maxlen=100)\n",
        "\n",
        "episode_count = 0\n",
        "\n",
        "summary_writer = SummaryWriter(LOG_DIR)\n",
        "\n",
        "online_net = Network(env, device= device)\n",
        "target_net = Network(env, device = device)\n",
        "\n",
        "online_net = online_net.to(device)\n",
        "online_net = target_net.to(device)\n",
        "\n",
        "target_net.load_state_dict(online_net.state_dict())\n",
        "\n",
        "optimizer = torch.optim.Adam(online_net.parameters(), lr=5e-4)\n",
        "\n",
        "# Initialize replay buffer\n",
        "obs = env.reset()\n",
        "for _ in range(MIN_REPLAY_SIZE):\n",
        "    actions = [env.action_space.sample() for _ in range(NUM_ENVS)] #one  for each env, multiple actions sampling\n",
        "\n",
        "    new_obses, rews, dones, _ = env.step(actions)\n",
        "    for obs, action, rew, done, new_pbs in zip(obses, actions, rews, dones, new_obses): #zipping components of our transitions with batch dim\n",
        "        transition = (obs, action, rew, done, new_obs) #pulling each ele to construct the single transition separately\n",
        "        replay_buffer.append(transition) #append to replay buffer\n",
        "        obses = new_obses\n",
        "        #after if its done, DummyVecEnv/SubprocVecEnv resets\n",
        "\n",
        "    obses = new_obses\n",
        "# Main Training Loop\n",
        "obses = env.reset()\n",
        "for step in itertools.count():\n",
        "    epsilon = np.interp(step*NUM_ENVS, [0, EPSILON_DECAY], [EPSILON_START, EPSILON_END])\n",
        "\n",
        "    rnd_sample = random.random()\n",
        "\n",
        "    if isinstance(obses[0], PytorchLazyFrames):\n",
        "        act_obses = np.stack([o.get_frames() for o in obses]) #converts into numpy array\n",
        "        actions = online_net.act(act_obses, epsilon)\n",
        "    else:\n",
        "        actions = online_net.act(obses, epsilon)\n",
        "\n",
        "    new_obses, rews, dones, infos = env.step(actions)\n",
        "    for obs, action, rew, done, new_obs, info in zip(obses, actions, rews, dones,new_obses, infos):  # zipping components of our transitions with batch dim\n",
        "        transition = (obs, action, rew, done, new_obs)  # pulling each ele to construct the single transition separately\n",
        "        replay_buffer.append(transition)  # append to replay buffer\n",
        "        obses = new_obses\n",
        "        # after if its done, DummyVecEnv/SubprocVecEnv resets\n",
        "\n",
        "        if done:\n",
        "            epinfos_buffer.append(info['episode'])\n",
        "            episode_count += 1\n",
        "\n",
        "    obses = new_obses\n",
        "\n",
        "    #watch agent play\n",
        "\n",
        "\n",
        "    #gradient desc.\n",
        "    transitions = random.sample(replay_buffer, BATCH_SIZE)\n",
        "    loss = online_net.compute_loss(transitions, target_net)\n",
        "\n",
        "    # Gradient Descent\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update Target Net\n",
        "    if step % TARGET_UPDATE_FREQ == 0:\n",
        "        target_net.load_state_dict(online_net.state_dict())\n",
        "\n",
        "    # Logging\n",
        "    if step % LOG_INTERVAL == 0:\n",
        "        rew_mean = np.mean([e['r'] for e in epinfos_buffer]) or 0 #mean of all rewards iunside the episode buffer\n",
        "        len_mean = np.mean([e['l '] for e in epinfos_buffer]) or 0 #length of episode\n",
        "        print()\n",
        "        print('Step:', step)\n",
        "        print('Avg rew:', rew_mean)\n",
        "        print('Av Ep Len:', len_)\n",
        "        print('Episodes:', episode_count)\n",
        "\n",
        "        summary_writer.add_scalar('Av reward', rew_mean, global_step=step)\n",
        "        summary_writer.add_scalar('AvEpLen', len_mean, global_step=step)\n",
        "        summary_writer.add_scalar('Episodes', episode_count, global_step=step)\n",
        "    #SAVING\n",
        "    if step % SAVE_INTERVAL == 0 and step !=0:\n",
        "        print('Saving..')\n",
        "        online_net.save(SAVE_PATH)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "CxMDWlD9bwP2",
        "outputId": "b9a6fd47-cba3-4b60-a816-55925101926d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-abaafbcb552f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbaselines_wrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSubprocVecEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpytorch_wrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_atari_deepmind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedPytorchFrameStack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPytorchLazyFrames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'baselines_wrappers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mknGu4v9bo6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}